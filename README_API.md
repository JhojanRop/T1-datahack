# üè• Medical Classification API

API REST simplificada para demostraci√≥n de clasificaci√≥n autom√°tica de literatura m√©dica usando BioBERT y Gemini LLM en el challenge de programaci√≥n.

## üéØ Caracter√≠sticas Principales

- **üß† Clasificaci√≥n H√≠brida**: Combina BioBERT fine-tuned con Gemini LLM para m√°xima precisi√≥n
- **üìö Dominios M√©dicos**: Cardiovascular, Neurol√≥gico, Oncol√≥gico, Hepatorenal
- **‚ö° Procesamiento R√°pido**: ~0.5s con BioBERT, ~2-5s con an√°lisis LLM profundo
- **ÔøΩ An√°lisis Completo**: M√©tricas macro/micro/weighted, matrices de confusi√≥n
- **ÔøΩ Comparaci√≥n de Modelos**: BioBERT vs LLM vs Sistema H√≠brido
- **üöÄ Demo Ready**: Sin autenticaci√≥n, directo al grano para el concurso

## üèóÔ∏è Arquitectura del Sistema

```
‚îú‚îÄ‚îÄ main.py                # API principal simplificada
‚îú‚îÄ‚îÄ .env                   # Configuraci√≥n API keys
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias
‚îú‚îÄ‚îÄ services/              # L√≥gica de clasificaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ biobert_classifier_enhanced.py    # BioBERT real
‚îÇ   ‚îú‚îÄ‚îÄ llm_classifier_enhanced.py        # Gemini LLM real
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_classifier_enhanced.py     # Sistema h√≠brido
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_enhanced.py              # Pipeline completo
‚îú‚îÄ‚îÄ utils/                 # Utilidades m√©dicas
‚îÇ   ‚îú‚îÄ‚îÄ medical_preprocessor.py           # Preprocesador
‚îÇ   ‚îú‚îÄ‚îÄ medical_evaluator.py              # Evaluador de m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ medical_label_analyzer.py         # An√°lisis de etiquetas
‚îú‚îÄ‚îÄ model/                 # Modelo BioBERT fine-tuned
‚îÇ   ‚îî‚îÄ‚îÄ biobert_finetuned_v3/
‚îî‚îÄ‚îÄ data/                  # Dataset del challenge
    ‚îî‚îÄ‚îÄ raw/
        ‚îî‚îÄ‚îÄ challenge_data-18-ago.csv
```

## üöÄ Inicio R√°pido

### 1. Configuraci√≥n del Entorno

```bash
# Navegar al proyecto
cd T1-datahack

# Instalar dependencias con uv
uv add fastapi uvicorn[standard] python-multipart pandas numpy torch transformers scikit-learn datasets python-dotenv google-generativeai

# O con pip
pip install -r requirements.txt
```

### 2. Configurar API Keys

```bash
# Ya tienes .env configurado con:
GEMINI_API_KEY=AIzaSyDNBFicMSLIWt50pkI2ux6sdFkx4kbzi0E
```

### 3. Ejecutar API

```bash
# Iniciar servidor
python main.py

# O con uvicorn
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 4. Verificar Instalaci√≥n

```bash
# Health check
curl http://localhost:8000/

# Documentaci√≥n interactiva
open http://localhost:8000/docs
```

## üß™ Demo y Testing

```bash
# Test de salud de la API
curl http://localhost:8000/

# Subir dataset de prueba (usa el del challenge)
curl -X POST "http://localhost:8000/classify/upload-dataset" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data/raw/challenge_data-18-ago.csv"

# Informaci√≥n de modelos cargados
curl http://localhost:8000/models/info
```

## üìö Endpoints Principales

### üè† Estado de la API

- `GET /` - Health check y estado de modelos cargados

### üß† Clasificaci√≥n

- `POST /classify/upload-dataset` - Subir CSV y clasificar con todos los modelos
- `GET /models/info` - Informaci√≥n detallada de los modelos cargados

### üìñ Documentaci√≥n

- `GET /docs` - Documentaci√≥n Swagger interactiva
- `GET /redoc` - Documentaci√≥n ReDoc alternativa

## üéØ Para el Concurso

### ‚úÖ Funcionalidades Implementadas

- **Subir Dataset CSV** con estructura `title`, `abstract`, `group`
- **An√°lisis con 3 Modelos** simult√°neamente:
  - BioBERT (modelo real fine-tuned)
  - LLM Gemini (limitado a 10 casos para demo)
  - Sistema H√≠brido (combinaci√≥n inteligente)
- **M√©tricas Completas**:
  - Accuracy, Precision, Recall, F1-Score
  - Macro, Micro y Weighted averaging
  - Matrices de confusi√≥n por etiqueta
- **An√°lisis de Distribuci√≥n** de etiquetas
- **Estad√≠sticas de Confianza** y rendimiento

## üß† M√©todos de Clasificaci√≥n

### 1. BioBERT (R√°pido)

- **Tiempo**: ~0.5s
- **Uso**: Clasificaci√≥n general r√°pida
- **Confianza**: An√°lisis multi-m√©todo

### 2. LLM/Gemini (Profundo)

- **Tiempo**: ~2-5s
- **Uso**: Casos complejos o ambiguos
- **Caracter√≠sticas**: Razonamiento expl√≠cito

### 3. H√≠brido (Recomendado)

- **Tiempo**: ~0.5-3s
- **Uso**: Routing inteligente autom√°tico
- **Optimizaci√≥n**: Mejor balance precisi√≥n/velocidad

## üìä Ejemplo de Uso

### Subir Dataset y Obtener An√°lisis Completo

```python
import requests

# Subir CSV con estructura del challenge
with open('data/raw/challenge_data-18-ago.csv', 'rb') as f:
    response = requests.post(
        "http://localhost:8000/classify/upload-dataset",
        files={"file": f}
    )

result = response.json()

# El resultado incluye:
print("üìä Info del dataset:", result['dataset_info'])
print("üß¨ Resultados BioBERT:", result['results']['biobert'])
print("ü§ñ Resultados LLM:", result['results']['llm'])
print("üîÑ Resultados H√≠brido:", result['results']['hybrid'])
print("üìà An√°lisis de etiquetas:", result['results']['label_analysis'])
```

### Ejemplo de Respuesta

```json
{
  "message": "Dataset procesado exitosamente",
  "dataset_info": {
    "total_articles": 50,
    "sample_titles": [
      "Effects of ACE inhibitors...",
      "Brain tumor classification..."
    ]
  },
  "results": {
    "biobert": {
      "model_name": "BioBERT Enhanced",
      "total_predictions": 50,
      "metrics": {
        "accuracy": 0.85,
        "precision_macro": 0.82,
        "recall_macro": 0.81,
        "f1_macro": 0.81
      },
      "confusion_matrices": {
        "cardiovascular": [
          [45, 5],
          [3, 47]
        ],
        "neurological": [
          [40, 10],
          [5, 45]
        ]
      }
    },
    "llm": {
      "model_name": "LLM (Gemini)",
      "total_predictions": 10,
      "metrics": {
        "accuracy": 0.9,
        "f1_macro": 0.88
      }
    },
    "hybrid": {
      "model_name": "Sistema H√≠brido",
      "metrics": {
        "accuracy": 0.92,
        "f1_macro": 0.9
      }
    }
  }
}
```

## ‚öôÔ∏è Configuraci√≥n

### Estructura del Dataset CSV

El CSV debe tener exactamente estas columnas:

- `title`: T√≠tulo del art√≠culo m√©dico
- `abstract`: Resumen cient√≠fico del art√≠culo
- `group`: Categor√≠a(s) m√©dica separadas por `|`

Ejemplo:

```csv
title;abstract;group
"Effects of ACE inhibitors";"This study examines...";"cardiovascular"
"Brain tumor analysis";"Machine learning approach...";"neurological|oncological"
```

## üîß Desarrollo

### Estructura de Proyecto Simplificada

```
T1-datahack/
‚îú‚îÄ‚îÄ main.py                              # API principal
‚îú‚îÄ‚îÄ .env                                 # API keys
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias
‚îú‚îÄ‚îÄ medical_classification_notebook.ipynb # Notebook original
‚îú‚îÄ‚îÄ services/                            # L√≥gica de modelos
‚îÇ   ‚îú‚îÄ‚îÄ biobert_classifier_enhanced.py  # BioBERT real
‚îÇ   ‚îú‚îÄ‚îÄ llm_classifier_enhanced.py      # Gemini LLM
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_classifier_enhanced.py   # Sistema h√≠brido
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_enhanced.py            # Pipeline completo
‚îú‚îÄ‚îÄ utils/                               # Utilidades m√©dicas
‚îÇ   ‚îú‚îÄ‚îÄ medical_preprocessor.py          # Preprocesador
‚îÇ   ‚îú‚îÄ‚îÄ medical_evaluator.py             # Evaluador
‚îÇ   ‚îî‚îÄ‚îÄ medical_label_analyzer.py        # An√°lisis etiquetas
‚îú‚îÄ‚îÄ model/                               # Modelo entrenado
‚îÇ   ‚îî‚îÄ‚îÄ biobert_finetuned_v3/
‚îî‚îÄ‚îÄ data/                                # Dataset challenge
    ‚îî‚îÄ‚îÄ raw/
        ‚îî‚îÄ‚îÄ challenge_data-18-ago.csv
```

### Dependencias Principales

- **FastAPI** - Framework web r√°pido
- **Transformers** - BioBERT y tokenizaci√≥n
- **PyTorch** - Deep learning
- **Google GenerativeAI** - Gemini LLM
- **Scikit-learn** - M√©tricas de evaluaci√≥n
- **Pandas/NumPy** - Procesamiento de datos

## üìà Performance y M√©tricas

### Tiempos de Procesamiento

- **BioBERT**: 0.3-0.7s por art√≠culo
- **LLM Gemini**: 2-5s por art√≠culo (limitado a 10 casos)
- **Sistema H√≠brido**: 0.5-3s promedio
- **Dataset completo**: 30-50 art√≠culos en ~20-30s

### M√©tricas Implementadas

#### M√©tricas de Clasificaci√≥n

- **Accuracy** - Precisi√≥n exacta
- **Precision** (macro, micro, weighted)
- **Recall** (macro, micro, weighted)
- **F1-Score** (macro, micro, weighted)
- **Hamming Loss** - Para multilabel

#### An√°lisis Avanzado

- **Matrices de Confusi√≥n** por etiqueta
- **Distribuci√≥n de Etiquetas** en el dataset
- **Estad√≠sticas de Confianza** por modelo
- **An√°lisis de Casos Obvios vs Dif√≠ciles**

## üèÜ Funcionalidades del Challenge

### üéØ Problema Multilabel

La API est√° dise√±ada espec√≠ficamente para el problema de clasificaci√≥n multilabel m√©dica:

- **4 Dominios**: cardiovascular, hepatorenal, neurological, oncological
- **M√∫ltiples etiquetas** por art√≠culo permitidas
- **Evaluaci√≥n robusta** con m√©tricas apropiadas para multilabel

### üß† Enfoque H√≠brido Inteligente

**BioBERT (90% casos obvios)**

- R√°pido y eficiente
- Fine-tuned en tu dataset
- Maneja casos claros con alta confianza

**LLM Gemini (10% casos dif√≠ciles)**

- An√°lisis profundo con razonamiento
- Para casos ambiguos o complejos
- Limitado a 10 casos en la demo

**Sistema H√≠brido**

- Routing autom√°tico basado en confianza
- Optimiza precisi√≥n vs velocidad
- Mejor rendimiento general

### üìä An√°lisis M√©dico Especializado

En lugar de estad√≠sticas b√°sicas, la API proporciona:

- **An√°lisis de co-ocurrencia** entre dominios m√©dicos
- **Distribuci√≥n inteligente** de etiquetas
- **M√©tricas espec√≠ficas** para literatura m√©dica
- **Insights de complejidad** de casos

## üêõ Troubleshooting

### Problemas Comunes

1. **Modelo BioBERT no encontrado**

   ```bash
   # Verifica que el modelo est√© en la ruta correcta:
   # ./model/biobert_finetuned_v3/
   # Debe contener: config.json, model.safetensors, tokenizer.json, etc.
   ```

2. **Error con Gemini API**

   ```bash
   # Verifica que la API key est√© en .env:
   GEMINI_API_KEY=tu_api_key_aqui

   # Si falla, el sistema usa fallback inteligente
   ```

3. **Error de dependencias**

   ```bash
   pip install --upgrade pip
   uv add fastapi uvicorn transformers torch scikit-learn
   ```

4. **Puerto ocupado**

   ```bash
   # Cambiar puerto en main.py l√≠nea final:
   uvicorn.run(app, host="0.0.0.0", port=8001)
   ```

5. **Dataset CSV mal formateado**
   ```bash
   # Verificar separador ; y columnas: title, abstract, group
   # Encoding UTF-8
   ```

### Logs y Debug

- **Consola**: Logs en tiempo real durante ejecuci√≥n
- **Errores**: Se muestran claramente con traceback
- **Estado de modelos**: Verificar en GET /models/info

## üìû Soporte y Uso

### üöÄ Para el Concurso

1. **Ejecutar API**: `python main.py`
2. **Abrir docs**: http://localhost:8000/docs
3. **Subir dataset**: POST /classify/upload-dataset
4. **Ver resultados**: JSON con m√©tricas de los 3 modelos

### üåê Integraci√≥n con v0

```javascript
// Para tu aplicaci√≥n web en v0
const uploadDataset = async (file) => {
  const formData = new FormData();
  formData.append("file", file);

  const response = await fetch(
    "http://localhost:8000/classify/upload-dataset",
    {
      method: "POST",
      body: formData,
    }
  );

  return response.json();
};
```

### ÔøΩ Endpoints Clave

- **Health**: `GET /`
- **Upload**: `POST /classify/upload-dataset`
- **Models**: `GET /models/info`
- **Docs**: `GET /docs`

---

**üè• Medical Classification API v2.0**  
_Clasificaci√≥n inteligente de literatura m√©dica para challenge de programaci√≥n_
